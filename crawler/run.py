# è§¦å‘çˆ¬å–ä»»åŠ¡

from crawler.tasks import fetch_url

# å¾…çˆ¬å–çš„ URL åˆ—è¡¨ï¼ˆåç»­å¯ä» A ç»„ API è·å–ï¼‰
urls = [
    "https://baidu.com",
    "https://juejin.cn",
    "https://github.com"
]

# å‘é€çˆ¬å–ä»»åŠ¡åˆ° Celery
for url in urls:
    fetch_url.delay(url)  # å¼‚æ­¥æ‰§è¡Œ
    print(f"ğŸ“¡ ä»»åŠ¡å·²å‘é€: {url}")